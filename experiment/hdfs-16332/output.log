JUnit version 4.13.2
2025-03-11 12:05:39,335 - INFO  [main:MiniKdc@225] - Configuration:
2025-03-11 12:05:39,337 - INFO  [main:MiniKdc@226] - ---------------------------------------------------------------
2025-03-11 12:05:39,338 - INFO  [main:MiniKdc@228] -   debug: false
2025-03-11 12:05:39,338 - INFO  [main:MiniKdc@228] -   transport: TCP
2025-03-11 12:05:39,338 - INFO  [main:MiniKdc@228] -   max.ticket.lifetime: 86400000
2025-03-11 12:05:39,338 - INFO  [main:MiniKdc@228] -   org.name: EXAMPLE
2025-03-11 12:05:39,338 - INFO  [main:MiniKdc@228] -   kdc.port: 0
2025-03-11 12:05:39,338 - INFO  [main:MiniKdc@228] -   org.domain: COM
2025-03-11 12:05:39,338 - INFO  [main:MiniKdc@228] -   max.renewable.lifetime: 604800000
2025-03-11 12:05:39,338 - INFO  [main:MiniKdc@228] -   instance: DefaultKrbServer
2025-03-11 12:05:39,338 - INFO  [main:MiniKdc@228] -   kdc.bind.address: localhost
2025-03-11 12:05:39,338 - INFO  [main:MiniKdc@230] - ---------------------------------------------------------------
2025-03-11 12:05:39,412 - INFO  [main:MiniKdc@285] - MiniKdc started.
.2025-03-11 12:05:39,862 - INFO  [Time-limited test:MiniDFSCluster@554] - starting cluster: numNameNodes=1, numDataNodes=1
2025-03-11 12:05:40,013 - WARN  [Time-limited test:NativeCodeLoader@60] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-03-11 12:05:40,066 - INFO  [Time-limited test:NameNode@1248] - Formatting using clusterid: testClusterID
2025-03-11 12:05:40,098 - INFO  [Time-limited test:FSEditLog@234] - Edit logging is async:true
2025-03-11 12:05:40,110 - INFO  [Time-limited test:FSNamesystem@859] - KeyProvider: null
2025-03-11 12:05:40,111 - INFO  [Time-limited test:FSNamesystemLock@142] - fsLock is fair: true
2025-03-11 12:05:40,111 - INFO  [Time-limited test:FSNamesystemLock@160] - Detailed lock hold time metrics enabled: false
2025-03-11 12:05:40,115 - INFO  [Time-limited test:FSNamesystem@898] - fsOwner                = root (auth:SIMPLE)
2025-03-11 12:05:40,115 - INFO  [Time-limited test:FSNamesystem@899] - supergroup             = supergroup
2025-03-11 12:05:40,115 - INFO  [Time-limited test:FSNamesystem@900] - isPermissionEnabled    = true
2025-03-11 12:05:40,115 - INFO  [Time-limited test:FSNamesystem@901] - isStoragePolicyEnabled = true
2025-03-11 12:05:40,115 - INFO  [Time-limited test:FSNamesystem@912] - HA Enabled: false
2025-03-11 12:05:40,138 - INFO  [Time-limited test:Util@428] - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-11 12:05:40,141 - INFO  [Time-limited test:Configuration@1441] - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2025-03-11 12:05:40,141 - INFO  [Time-limited test:DatanodeManager@325] - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2025-03-11 12:05:40,141 - INFO  [Time-limited test:DatanodeManager@332] - dfs.namenode.datanode.registration.ip-hostname-check=true
2025-03-11 12:05:40,143 - INFO  [Time-limited test:InvalidateBlocks@77] - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2025-03-11 12:05:40,143 - INFO  [Time-limited test:InvalidateBlocks@83] - The block deletion will start around 2025 Mar 11 12:05:40
2025-03-11 12:05:40,144 - INFO  [Time-limited test:LightWeightGSet@395] - Computing capacity for map BlocksMap
2025-03-11 12:05:40,144 - INFO  [Time-limited test:LightWeightGSet@396] - VM type       = 64-bit
2025-03-11 12:05:40,145 - INFO  [Time-limited test:LightWeightGSet@397] - 2.0% max memory 6.9 GB = 141.2 MB
2025-03-11 12:05:40,145 - INFO  [Time-limited test:LightWeightGSet@402] - capacity      = 2^24 = 16777216 entries
2025-03-11 12:05:40,152 - INFO  [Time-limited test:BlockManager@5343] - Storage policy satisfier is disabled
2025-03-11 12:05:40,152 - INFO  [Time-limited test:BlockManager@618] - dfs.block.access.token.enable = true
2025-03-11 12:05:40,152 - INFO  [Time-limited test:BlockManager@640] - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2025-03-11 12:05:40,156 - INFO  [Time-limited test:BlockTokenSecretManager@155] - Block token key range: [0, 2147483647)
2025-03-11 12:05:40,159 - INFO  [Time-limited test:BlockManagerSafeMode$SafeModeMonitor@656] - Using 1000 as SafeModeMonitor Interval
2025-03-11 12:05:40,159 - INFO  [Time-limited test:BlockManagerSafeMode@161] - dfs.namenode.safemode.threshold-pct = 0.999
2025-03-11 12:05:40,159 - INFO  [Time-limited test:BlockManagerSafeMode@162] - dfs.namenode.safemode.min.datanodes = 0
2025-03-11 12:05:40,159 - INFO  [Time-limited test:BlockManagerSafeMode@164] - dfs.namenode.safemode.extension = 0
2025-03-11 12:05:40,160 - INFO  [Time-limited test:BlockManager@604] - defaultReplication         = 1
2025-03-11 12:05:40,160 - INFO  [Time-limited test:BlockManager@605] - maxReplication             = 512
2025-03-11 12:05:40,160 - INFO  [Time-limited test:BlockManager@606] - minReplication             = 1
2025-03-11 12:05:40,160 - INFO  [Time-limited test:BlockManager@607] - maxReplicationStreams      = 2
2025-03-11 12:05:40,160 - INFO  [Time-limited test:BlockManager@608] - redundancyRecheckInterval  = 3000ms
2025-03-11 12:05:40,160 - INFO  [Time-limited test:BlockManager@609] - encryptDataTransfer        = false
2025-03-11 12:05:40,160 - INFO  [Time-limited test:BlockManager@610] - maxNumBlocksToLog          = 1000
2025-03-11 12:05:40,171 - INFO  [Time-limited test:SerialNumberManager@51] - GLOBAL serial map: bits=29 maxEntries=536870911
2025-03-11 12:05:40,172 - INFO  [Time-limited test:SerialNumberManager@51] - USER serial map: bits=24 maxEntries=16777215
2025-03-11 12:05:40,172 - INFO  [Time-limited test:SerialNumberManager@51] - GROUP serial map: bits=24 maxEntries=16777215
2025-03-11 12:05:40,172 - INFO  [Time-limited test:SerialNumberManager@51] - XATTR serial map: bits=24 maxEntries=16777215
2025-03-11 12:05:40,178 - INFO  [Time-limited test:LightWeightGSet@395] - Computing capacity for map INodeMap
2025-03-11 12:05:40,178 - INFO  [Time-limited test:LightWeightGSet@396] - VM type       = 64-bit
2025-03-11 12:05:40,178 - INFO  [Time-limited test:LightWeightGSet@397] - 1.0% max memory 6.9 GB = 70.6 MB
2025-03-11 12:05:40,178 - INFO  [Time-limited test:LightWeightGSet@402] - capacity      = 2^23 = 8388608 entries
2025-03-11 12:05:40,180 - INFO  [Time-limited test:FSDirectory@335] - ACLs enabled? true
2025-03-11 12:05:40,180 - INFO  [Time-limited test:FSDirectory@339] - POSIX ACL inheritance enabled? true
2025-03-11 12:05:40,180 - INFO  [Time-limited test:FSDirectory@343] - XAttrs enabled? true
2025-03-11 12:05:40,180 - INFO  [Time-limited test:FSDirectory@406] - Caching file names occurring more than 10 times
2025-03-11 12:05:40,183 - INFO  [Time-limited test:SnapshotManager@163] - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2025-03-11 12:05:40,183 - INFO  [Time-limited test:SnapshotManager@176] - dfs.namenode.snapshot.deletion.ordered = false
2025-03-11 12:05:40,184 - INFO  [Time-limited test:DirectoryDiffListFactory@43] - SkipList is disabled
2025-03-11 12:05:40,186 - INFO  [Time-limited test:LightWeightGSet@395] - Computing capacity for map cachedBlocks
2025-03-11 12:05:40,186 - INFO  [Time-limited test:LightWeightGSet@396] - VM type       = 64-bit
2025-03-11 12:05:40,186 - INFO  [Time-limited test:LightWeightGSet@397] - 0.25% max memory 6.9 GB = 17.6 MB
2025-03-11 12:05:40,186 - INFO  [Time-limited test:LightWeightGSet@402] - capacity      = 2^21 = 2097152 entries
2025-03-11 12:05:40,243 - INFO  [Time-limited test:TopMetrics@76] - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2025-03-11 12:05:40,243 - INFO  [Time-limited test:TopMetrics@78] - NNTop conf: dfs.namenode.top.num.users = 10
2025-03-11 12:05:40,243 - INFO  [Time-limited test:TopMetrics@80] - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2025-03-11 12:05:40,245 - INFO  [Time-limited test:FSNamesystem@1142] - Retry cache on namenode is enabled
2025-03-11 12:05:40,245 - INFO  [Time-limited test:FSNamesystem@1150] - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2025-03-11 12:05:40,246 - INFO  [Time-limited test:LightWeightGSet@395] - Computing capacity for map NameNodeRetryCache
2025-03-11 12:05:40,246 - INFO  [Time-limited test:LightWeightGSet@396] - VM type       = 64-bit
2025-03-11 12:05:40,246 - INFO  [Time-limited test:LightWeightGSet@397] - 0.029999999329447746% max memory 6.9 GB = 2.1 MB
2025-03-11 12:05:40,246 - INFO  [Time-limited test:LightWeightGSet@402] - capacity      = 2^18 = 262144 entries
2025-03-11 12:05:40,284 - INFO  [Time-limited test:FSImage@186] - Allocated new BlockPoolId: BP-2070535275-192.168.1.5-1741694740280
2025-03-11 12:05:40,290 - INFO  [Time-limited test:NNStorage@595] - Storage directory /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-1 has been successfully formatted.
2025-03-11 12:05:40,292 - INFO  [Time-limited test:NNStorage@595] - Storage directory /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-2 has been successfully formatted.
2025-03-11 12:05:40,315 - INFO  [FSImageSaver for /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS:FSImageFormatProtobuf$Saver@732] - Saving image file /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2025-03-11 12:05:40,315 - INFO  [FSImageSaver for /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS:FSImageFormatProtobuf$Saver@732] - Saving image file /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2025-03-11 12:05:40,384 - INFO  [FSImageSaver for /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS:FSImageFormatProtobuf$Saver@736] - Image file /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2025-03-11 12:05:40,384 - INFO  [FSImageSaver for /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS:FSImageFormatProtobuf$Saver@736] - Image file /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2025-03-11 12:05:40,393 - INFO  [Time-limited test:NNStorageRetentionManager@202] - Going to retain 1 images with txid >= 0
2025-03-11 12:05:40,415 - INFO  [Time-limited test:FSNamesystem@1493] - Stopping services started for active state
2025-03-11 12:05:40,415 - INFO  [Time-limited test:FSNamesystem@1597] - Stopping services started for standby state
2025-03-11 12:05:40,416 - INFO  [Time-limited test:NameNode@1706] - createNameNode []
2025-03-11 12:05:40,468 - INFO  [Time-limited test:MetricsConfig@120] - Loaded properties from hadoop-metrics2.properties
2025-03-11 12:05:40,513 - INFO  [Time-limited test:MetricsSystemImpl@378] - Scheduled Metric snapshot period at 0 second(s).
2025-03-11 12:05:40,513 - INFO  [Time-limited test:MetricsSystemImpl@191] - NameNode metrics system started
2025-03-11 12:05:40,516 - INFO  [Time-limited test:NameNodeUtils@79] - fs.defaultFS is hdfs://127.0.0.1:0
2025-03-11 12:05:40,544 - INFO  [pool-1-thread-1:KdcRequest@651] - The preauth data is empty.
2025-03-11 12:05:40,549 - INFO  [pool-1-thread-1:KdcHandler@177] - KRB error occurred while processing request:Additional pre-authentication required
2025-03-11 12:05:40,577 - INFO  [pool-1-thread-1:AsRequest@112] - AS_REQ ISSUE: authtime 1741694740575,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2025-03-11 12:05:40,581 - INFO  [Time-limited test:UserGroupInformation@1128] - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file hdfs.keytab. Keytab auto renewal enabled : false
2025-03-11 12:05:40,601 - INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@47ce9c23:JvmPauseMonitor$Monitor@185] - Starting JVM pause monitor
2025-03-11 12:05:40,609 - INFO  [Time-limited test:DFSUtil@1736] - Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2025-03-11 12:05:40,612 - INFO  [Time-limited test:DFSUtil@1746] - Starting web server as: HTTP/localhost@EXAMPLE.COM
2025-03-11 12:05:40,612 - INFO  [Time-limited test:DFSUtil@1771] - Starting Web-server for hdfs at: https://localhost:0
2025-03-11 12:05:40,621 - INFO  [Time-limited test:Log@170] - Logging initialized @1580ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-11 12:05:40,681 - WARN  [Time-limited test:AuthenticationFilter@240] - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-11 12:05:40,683 - INFO  [Time-limited test:HttpRequestLog@82] - Http request log for http.requests.namenode is not defined
2025-03-11 12:05:40,688 - INFO  [Time-limited test:HttpServer2@1155] - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-11 12:05:40,690 - INFO  [Time-limited test:HttpServer2@1128] - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2025-03-11 12:05:40,690 - INFO  [Time-limited test:HttpServer2@1138] - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-11 12:05:40,693 - INFO  [Time-limited test:HttpServer2@1128] - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2025-03-11 12:05:40,693 - INFO  [Time-limited test:HttpServer2@1138] - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2025-03-11 12:05:40,731 - INFO  [Time-limited test:HttpServer2@982] - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2025-03-11 12:05:40,736 - INFO  [Time-limited test:HttpServer2@1386] - Jetty bound to port 37181
2025-03-11 12:05:40,737 - INFO  [Time-limited test:Server@375] - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_442-8u442-b06~us1-0ubuntu1~24.04-b06
2025-03-11 12:05:40,753 - INFO  [Time-limited test:DefaultSessionIdManager@334] - DefaultSessionIdManager workerName=node0
2025-03-11 12:05:40,754 - INFO  [Time-limited test:DefaultSessionIdManager@339] - No SessionScavenger set, using defaults
2025-03-11 12:05:40,755 - INFO  [Time-limited test:HouseKeeper@132] - node0 Scavenging every 660000ms
2025-03-11 12:05:40,765 - WARN  [Time-limited test:AuthenticationFilter@240] - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-11 12:05:40,767 - INFO  [Time-limited test:ContextHandler@915] - Started o.e.j.s.ServletContextHandler@26c8965c{static,/static,file:///home/sebastiaoamaro/phd/torefidevel/rw/Anduril/systems/hdfs-16332/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2025-03-11 12:05:40,799 - INFO  [Time-limited test:ContextHandler@915] - Started o.e.j.w.WebAppContext@ed8a801{hdfs,/,file:///home/sebastiaoamaro/phd/torefidevel/rw/Anduril/systems/hdfs-16332/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{file:/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/systems/hdfs-16332/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs}
2025-03-11 12:05:40,808 - INFO  [Time-limited test:SslContextFactory@358] - x509=X509@6541c152(server,h=[localhost],a=[],w=[]) for Server@37ceaa92[provider=null,keyStore=file:///home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/SaslDataTransferTestCase/serverKS.jks,trustStore=file:///home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/SaslDataTransferTestCase/trustKS.jks]
2025-03-11 12:05:40,812 - INFO  [Time-limited test:AbstractConnector@331] - Started ServerConnector@5f3ff011{SSL, (ssl, http/1.1)}{localhost:37181}
2025-03-11 12:05:40,812 - INFO  [Time-limited test:Server@415] - Started @1771ms
2025-03-11 12:05:40,817 - INFO  [Time-limited test:FSEditLog@234] - Edit logging is async:true
2025-03-11 12:05:40,824 - INFO  [Time-limited test:FSNamesystem@859] - KeyProvider: null
2025-03-11 12:05:40,824 - INFO  [Time-limited test:FSNamesystemLock@142] - fsLock is fair: true
2025-03-11 12:05:40,824 - INFO  [Time-limited test:FSNamesystemLock@160] - Detailed lock hold time metrics enabled: false
2025-03-11 12:05:40,824 - INFO  [Time-limited test:FSNamesystem@898] - fsOwner                = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2025-03-11 12:05:40,824 - INFO  [Time-limited test:FSNamesystem@899] - supergroup             = supergroup
2025-03-11 12:05:40,824 - INFO  [Time-limited test:FSNamesystem@900] - isPermissionEnabled    = true
2025-03-11 12:05:40,824 - INFO  [Time-limited test:FSNamesystem@901] - isStoragePolicyEnabled = true
2025-03-11 12:05:40,824 - INFO  [Time-limited test:FSNamesystem@912] - HA Enabled: false
2025-03-11 12:05:40,824 - INFO  [Time-limited test:Util@428] - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-11 12:05:40,824 - INFO  [Time-limited test:DatanodeManager@325] - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2025-03-11 12:05:40,824 - INFO  [Time-limited test:DatanodeManager@332] - dfs.namenode.datanode.registration.ip-hostname-check=true
2025-03-11 12:05:40,825 - INFO  [Time-limited test:InvalidateBlocks@77] - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2025-03-11 12:05:40,825 - INFO  [Time-limited test:InvalidateBlocks@83] - The block deletion will start around 2025 Mar 11 12:05:40
2025-03-11 12:05:40,825 - INFO  [Time-limited test:LightWeightGSet@395] - Computing capacity for map BlocksMap
2025-03-11 12:05:40,825 - INFO  [Time-limited test:LightWeightGSet@396] - VM type       = 64-bit
2025-03-11 12:05:40,825 - INFO  [Time-limited test:LightWeightGSet@397] - 2.0% max memory 6.9 GB = 141.2 MB
2025-03-11 12:05:40,825 - INFO  [Time-limited test:LightWeightGSet@402] - capacity      = 2^24 = 16777216 entries
2025-03-11 12:05:40,844 - INFO  [Time-limited test:BlockManager@5343] - Storage policy satisfier is disabled
2025-03-11 12:05:40,844 - INFO  [Time-limited test:BlockManager@618] - dfs.block.access.token.enable = true
2025-03-11 12:05:40,844 - INFO  [Time-limited test:BlockManager@640] - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2025-03-11 12:05:40,844 - INFO  [Time-limited test:BlockTokenSecretManager@155] - Block token key range: [0, 2147483647)
2025-03-11 12:05:40,844 - INFO  [Time-limited test:BlockManagerSafeMode$SafeModeMonitor@656] - Using 1000 as SafeModeMonitor Interval
2025-03-11 12:05:40,844 - INFO  [Time-limited test:BlockManagerSafeMode@161] - dfs.namenode.safemode.threshold-pct = 0.999
2025-03-11 12:05:40,845 - INFO  [Time-limited test:BlockManagerSafeMode@162] - dfs.namenode.safemode.min.datanodes = 0
2025-03-11 12:05:40,845 - INFO  [Time-limited test:BlockManagerSafeMode@164] - dfs.namenode.safemode.extension = 0
2025-03-11 12:05:40,845 - INFO  [Time-limited test:BlockManager@604] - defaultReplication         = 1
2025-03-11 12:05:40,845 - INFO  [Time-limited test:BlockManager@605] - maxReplication             = 512
2025-03-11 12:05:40,845 - INFO  [Time-limited test:BlockManager@606] - minReplication             = 1
2025-03-11 12:05:40,845 - INFO  [Time-limited test:BlockManager@607] - maxReplicationStreams      = 2
2025-03-11 12:05:40,845 - INFO  [Time-limited test:BlockManager@608] - redundancyRecheckInterval  = 3000ms
2025-03-11 12:05:40,845 - INFO  [Time-limited test:BlockManager@609] - encryptDataTransfer        = false
2025-03-11 12:05:40,845 - INFO  [Time-limited test:BlockManager@610] - maxNumBlocksToLog          = 1000
2025-03-11 12:05:40,845 - INFO  [Time-limited test:LightWeightGSet@395] - Computing capacity for map INodeMap
2025-03-11 12:05:40,845 - INFO  [Time-limited test:LightWeightGSet@396] - VM type       = 64-bit
2025-03-11 12:05:40,845 - INFO  [Time-limited test:LightWeightGSet@397] - 1.0% max memory 6.9 GB = 70.6 MB
2025-03-11 12:05:40,845 - INFO  [Time-limited test:LightWeightGSet@402] - capacity      = 2^23 = 8388608 entries
2025-03-11 12:05:40,847 - INFO  [Time-limited test:FSDirectory@335] - ACLs enabled? true
2025-03-11 12:05:40,847 - INFO  [Time-limited test:FSDirectory@339] - POSIX ACL inheritance enabled? true
2025-03-11 12:05:40,847 - INFO  [Time-limited test:FSDirectory@343] - XAttrs enabled? true
2025-03-11 12:05:40,847 - INFO  [Time-limited test:FSDirectory@406] - Caching file names occurring more than 10 times
2025-03-11 12:05:40,847 - INFO  [Time-limited test:SnapshotManager@163] - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2025-03-11 12:05:40,847 - INFO  [Time-limited test:SnapshotManager@176] - dfs.namenode.snapshot.deletion.ordered = false
2025-03-11 12:05:40,847 - INFO  [Time-limited test:DirectoryDiffListFactory@43] - SkipList is disabled
2025-03-11 12:05:40,847 - INFO  [Time-limited test:LightWeightGSet@395] - Computing capacity for map cachedBlocks
2025-03-11 12:05:40,847 - INFO  [Time-limited test:LightWeightGSet@396] - VM type       = 64-bit
2025-03-11 12:05:40,847 - INFO  [Time-limited test:LightWeightGSet@397] - 0.25% max memory 6.9 GB = 17.6 MB
2025-03-11 12:05:40,848 - INFO  [Time-limited test:LightWeightGSet@402] - capacity      = 2^21 = 2097152 entries
2025-03-11 12:05:40,848 - INFO  [Time-limited test:TopMetrics@76] - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2025-03-11 12:05:40,848 - INFO  [Time-limited test:TopMetrics@78] - NNTop conf: dfs.namenode.top.num.users = 10
2025-03-11 12:05:40,848 - INFO  [Time-limited test:TopMetrics@80] - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2025-03-11 12:05:40,848 - INFO  [Time-limited test:FSNamesystem@1142] - Retry cache on namenode is enabled
2025-03-11 12:05:40,848 - INFO  [Time-limited test:FSNamesystem@1150] - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2025-03-11 12:05:40,848 - INFO  [Time-limited test:LightWeightGSet@395] - Computing capacity for map NameNodeRetryCache
2025-03-11 12:05:40,848 - INFO  [Time-limited test:LightWeightGSet@396] - VM type       = 64-bit
2025-03-11 12:05:40,848 - INFO  [Time-limited test:LightWeightGSet@397] - 0.029999999329447746% max memory 6.9 GB = 2.1 MB
2025-03-11 12:05:40,848 - INFO  [Time-limited test:LightWeightGSet@402] - capacity      = 2^18 = 262144 entries
2025-03-11 12:05:40,851 - INFO  [Time-limited test:Storage$StorageDirectory@948] - Lock on /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 12359@laptop
2025-03-11 12:05:40,853 - INFO  [Time-limited test:Storage$StorageDirectory@948] - Lock on /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 12359@laptop
2025-03-11 12:05:40,854 - INFO  [Time-limited test:FileJournalManager@428] - Recovering unfinalized segments in /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-1/current
2025-03-11 12:05:40,854 - INFO  [Time-limited test:FileJournalManager@428] - Recovering unfinalized segments in /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-2/current
2025-03-11 12:05:40,855 - INFO  [Time-limited test:FSImage@734] - No edit log streams selected.
2025-03-11 12:05:40,855 - INFO  [Time-limited test:FSImage@800] - Planning to load image: FSImageFile(file=/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2025-03-11 12:05:40,868 - INFO  [Time-limited test:FSImageFormatPBINode$Loader@413] - Loading 1 INodes.
2025-03-11 12:05:40,869 - INFO  [Time-limited test:FSImageFormatPBINode$Loader@371] - Successfully loaded 1 inodes
2025-03-11 12:05:40,871 - INFO  [Time-limited test:FSImageFormatPBINode$Loader@344] - Completed update blocks map and name cache, total waiting duration 0ms.
2025-03-11 12:05:40,872 - INFO  [Time-limited test:FSImageFormatProtobuf$Loader@255] - Loaded FSImage in 0 seconds.
2025-03-11 12:05:40,873 - INFO  [Time-limited test:FSImage@978] - Loaded image for txid 0 from /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2025-03-11 12:05:40,875 - INFO  [Time-limited test:FSNamesystem@1264] - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2025-03-11 12:05:40,875 - INFO  [Time-limited test:FSEditLog@1410] - Starting log segment at 1
2025-03-11 12:05:40,894 - INFO  [Time-limited test:NameCache@143] - initialized with 0 entries 0 lookups
2025-03-11 12:05:40,894 - INFO  [Time-limited test:FSNamesystem@831] - Finished loading FSImage in 44 msecs
2025-03-11 12:05:41,101 - INFO  [Time-limited test:NameNodeRpcServer@444] - RPC server is binding to localhost:0
2025-03-11 12:05:41,101 - INFO  [Time-limited test:NameNodeRpcServer@449] - Enable NameNode state context:false
2025-03-11 12:05:41,106 - INFO  [Time-limited test:CallQueueManager@93] - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-11 12:05:41,113 - INFO  [Socket Reader #1 for port 0:Server$Listener$Reader@1392] - Starting Socket Reader #1 for port 0
2025-03-11 12:05:41,231 - INFO  [Listener at localhost/35431:NameNode@775] - Clients are to use localhost:35431 to access this namenode/service.
2025-03-11 12:05:41,232 - INFO  [Listener at localhost/35431:FSNamesystem@5584] - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2025-03-11 12:05:41,239 - INFO  [Listener at localhost/35431:LeaseManager@166] - Number of blocks under construction: 0
2025-03-11 12:05:41,244 - INFO  [Listener at localhost/35431:DatanodeAdminDefaultMonitor@116] - Initialized the Default Decommission and Maintenance monitor
2025-03-11 12:05:41,246 - INFO  [Listener at localhost/35431:BlockManager@5081] - initializing replication queues
2025-03-11 12:05:41,246 - INFO  [Listener at localhost/35431:BlockManagerSafeMode@409] - STATE* Leaving safe mode after 0 secs
2025-03-11 12:05:41,246 - INFO  [Listener at localhost/35431:BlockManagerSafeMode@415] - STATE* Network topology has 0 racks and 0 datanodes
2025-03-11 12:05:41,246 - INFO  [Listener at localhost/35431:BlockManagerSafeMode@417] - STATE* UnderReplicatedBlocks has 0 blocks
2025-03-11 12:05:41,247 - INFO  [Listener at localhost/35431:AbstractDelegationTokenSecretManager@367] - Updating the current master key for generating delegation tokens
2025-03-11 12:05:41,250 - INFO  [Thread[Thread-31,5,main]:AbstractDelegationTokenSecretManager$ExpiredTokenRemover@701] - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2025-03-11 12:05:41,250 - INFO  [Thread[Thread-31,5,main]:AbstractDelegationTokenSecretManager@367] - Updating the current master key for generating delegation tokens
2025-03-11 12:05:41,255 - INFO  [Reconstruction Queue Initializer:BlockManager@3726] - Total number of blocks            = 0
2025-03-11 12:05:41,255 - INFO  [Reconstruction Queue Initializer:BlockManager@3727] - Number of invalid blocks          = 0
2025-03-11 12:05:41,255 - INFO  [Reconstruction Queue Initializer:BlockManager@3728] - Number of under-replicated blocks = 0
2025-03-11 12:05:41,255 - INFO  [Reconstruction Queue Initializer:BlockManager@3729] - Number of  over-replicated blocks = 0
2025-03-11 12:05:41,255 - INFO  [Reconstruction Queue Initializer:BlockManager@3731] - Number of blocks being written    = 0
2025-03-11 12:05:41,255 - INFO  [Reconstruction Queue Initializer:BlockManager@3734] - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2025-03-11 12:05:41,267 - INFO  [IPC Server Responder:Server$Responder@1631] - IPC Server Responder: starting
2025-03-11 12:05:41,267 - INFO  [IPC Server listener on 0:Server$Listener@1471] - IPC Server listener on 0: starting
2025-03-11 12:05:41,269 - INFO  [Listener at localhost/35431:NameNode@892] - NameNode RPC up at: localhost/127.0.0.1:35431
2025-03-11 12:05:41,270 - INFO  [Listener at localhost/35431:FSNamesystem@1376] - Starting services required for active state
2025-03-11 12:05:41,270 - INFO  [Listener at localhost/35431:FSDirectory@849] - Initializing quota with 12 thread(s)
2025-03-11 12:05:41,272 - INFO  [Listener at localhost/35431:FSDirectory@858] - Quota initialization completed in 2 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0, NVDIMM=0
2025-03-11 12:05:41,274 - INFO  [CacheReplicationMonitor(1829593987):CacheReplicationMonitor@160] - Starting CacheReplicationMonitor with interval 30000 milliseconds
2025-03-11 12:05:41,278 - INFO  [Listener at localhost/35431:MiniDFSCluster@1726] - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1,[DISK]file:/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2
2025-03-11 12:05:41,285 - INFO  [pool-1-thread-1:KdcRequest@651] - The preauth data is empty.
2025-03-11 12:05:41,285 - INFO  [pool-1-thread-1:KdcHandler@177] - KRB error occurred while processing request:Additional pre-authentication required
2025-03-11 12:05:41,288 - INFO  [pool-1-thread-1:AsRequest@112] - AS_REQ ISSUE: authtime 1741694741287,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2025-03-11 12:05:41,289 - INFO  [Listener at localhost/35431:UserGroupInformation@1128] - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file hdfs.keytab. Keytab auto renewal enabled : false
2025-03-11 12:05:41,320 - INFO  [Listener at localhost/35431:ThrottledAsyncChecker@137] - Scheduling a check for [DISK]file:/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1
2025-03-11 12:05:41,328 - INFO  [Listener at localhost/35431:ThrottledAsyncChecker@137] - Scheduling a check for [DISK]file:/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2
2025-03-11 12:05:41,334 - INFO  [Listener at localhost/35431:MetricsSystemImpl@158] - DataNode metrics system started (again)
2025-03-11 12:05:41,336 - INFO  [Listener at localhost/35431:Util@428] - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-11 12:05:41,337 - INFO  [Listener at localhost/35431:BlockScanner@201] - Initialized block scanner with targetBytesPerSec 1048576
2025-03-11 12:05:41,340 - INFO  [Listener at localhost/35431:DataNode@505] - Configured hostname is 127.0.0.1
2025-03-11 12:05:41,340 - INFO  [Listener at localhost/35431:Util@428] - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-11 12:05:41,342 - INFO  [Listener at localhost/35431:DataNode@1465] - Starting DataNode with maxLockedMemory = 0
2025-03-11 12:05:41,345 - INFO  [Listener at localhost/35431:DataNode@1228] - Opened streaming server at /127.0.0.1:40477
2025-03-11 12:05:41,346 - INFO  [Listener at localhost/35431:DataXceiverServer$BlockBalanceThrottler@94] - Balancing bandwidth is 104857600 bytes/s
2025-03-11 12:05:41,346 - INFO  [Listener at localhost/35431:DataXceiverServer$BlockBalanceThrottler@95] - Number threads for balancing is 100
2025-03-11 12:05:41,351 - WARN  [Listener at localhost/35431:AuthenticationFilter@240] - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-11 12:05:41,351 - INFO  [Listener at localhost/35431:HttpRequestLog@82] - Http request log for http.requests.datanode is not defined
2025-03-11 12:05:41,353 - INFO  [Listener at localhost/35431:HttpServer2@1155] - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-11 12:05:41,354 - INFO  [Listener at localhost/35431:HttpServer2@1128] - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2025-03-11 12:05:41,354 - INFO  [Listener at localhost/35431:HttpServer2@1138] - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-11 12:05:41,356 - INFO  [Listener at localhost/35431:HttpServer2@1386] - Jetty bound to port 43901
2025-03-11 12:05:41,356 - INFO  [Listener at localhost/35431:Server@375] - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_442-8u442-b06~us1-0ubuntu1~24.04-b06
2025-03-11 12:05:41,356 - INFO  [Listener at localhost/35431:DefaultSessionIdManager@334] - DefaultSessionIdManager workerName=node0
2025-03-11 12:05:41,356 - INFO  [Listener at localhost/35431:DefaultSessionIdManager@339] - No SessionScavenger set, using defaults
2025-03-11 12:05:41,356 - INFO  [Listener at localhost/35431:HouseKeeper@132] - node0 Scavenging every 660000ms
2025-03-11 12:05:41,357 - INFO  [Listener at localhost/35431:ContextHandler@915] - Started o.e.j.s.ServletContextHandler@6846882a{static,/static,file:///home/sebastiaoamaro/phd/torefidevel/rw/Anduril/systems/hdfs-16332/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2025-03-11 12:05:41,361 - INFO  [Listener at localhost/35431:ContextHandler@915] - Started o.e.j.w.WebAppContext@bc8c9ac{datanode,/,file:///home/sebastiaoamaro/phd/torefidevel/rw/Anduril/systems/hdfs-16332/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{file:/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/systems/hdfs-16332/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode}
2025-03-11 12:05:41,362 - INFO  [Listener at localhost/35431:AbstractConnector@331] - Started ServerConnector@2896a8b5{HTTP/1.1, (http/1.1)}{localhost:43901}
2025-03-11 12:05:41,362 - INFO  [Listener at localhost/35431:Server@415] - Started @2321ms
2025-03-11 12:05:41,438 - WARN  [Listener at localhost/35431:RestCsrfPreventionFilterHandler@75] - Got null for restCsrfPreventionFilter - will not do any filtering.
2025-03-11 12:05:41,493 - INFO  [Listener at localhost/35431:DatanodeHttpServer@339] - Listening HTTPS traffic on /127.0.0.1:36845
2025-03-11 12:05:41,493 - INFO  [Listener at localhost/35431:DataNode@1493] - dnUserName = hdfs/localhost@EXAMPLE.COM
2025-03-11 12:05:41,493 - INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1b0aada6:JvmPauseMonitor$Monitor@185] - Starting JVM pause monitor
2025-03-11 12:05:41,493 - INFO  [Listener at localhost/35431:DataNode@1494] - supergroup = supergroup
2025-03-11 12:05:41,500 - INFO  [Listener at localhost/35431:CallQueueManager@93] - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-11 12:05:41,501 - INFO  [Socket Reader #1 for port 0:Server$Listener$Reader@1392] - Starting Socket Reader #1 for port 0
2025-03-11 12:05:41,503 - INFO  [Listener at localhost/46265:DataNode@1115] - Opened IPC server at /127.0.0.1:46265
2025-03-11 12:05:41,514 - INFO  [Listener at localhost/46265:BlockPoolManager@150] - Refresh request received for nameservices: null
2025-03-11 12:05:41,514 - INFO  [Listener at localhost/46265:BlockPoolManager@211] - Starting BPOfferServices for nameservices: <default>
2025-03-11 12:05:41,519 - INFO  [Thread-67:BPServiceActor@871] - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35431 starting to offer service
2025-03-11 12:05:41,521 - INFO  [IPC Server Responder:Server$Responder@1631] - IPC Server Responder: starting
2025-03-11 12:05:41,522 - INFO  [IPC Server listener on 0:Server$Listener@1471] - IPC Server listener on 0: starting
2025-03-11 12:05:41,593 - INFO  [pool-1-thread-1:TgsRequest@115] - TGS_REQ ISSUE: authtime 1741694741593,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2025-03-11 12:05:41,604 - INFO  [Socket Reader #1 for port 0:Server$Connection@2189] - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS) from 127.0.0.1:39969
2025-03-11 12:05:41,679 - INFO  [Thread-67:BPOfferService@381] - Acknowledging ACTIVE Namenode during handshake Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35431
2025-03-11 12:05:41,680 - INFO  [Thread-67:DataStorage@356] - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2025-03-11 12:05:41,681 - INFO  [Thread-67:Storage$StorageDirectory@948] - Lock on /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 12359@laptop
2025-03-11 12:05:41,681 - INFO  [Thread-67:DataStorage@284] - Storage directory with location [DISK]file:/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1 is not formatted for namespace 1783479077. Formatting...
2025-03-11 12:05:41,682 - INFO  [Thread-67:DataStorage@160] - Generated new storageID DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b for directory /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1 
2025-03-11 12:05:41,685 - INFO  [Thread-67:Storage$StorageDirectory@948] - Lock on /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 12359@laptop
2025-03-11 12:05:41,685 - INFO  [Thread-67:DataStorage@284] - Storage directory with location [DISK]file:/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2 is not formatted for namespace 1783479077. Formatting...
2025-03-11 12:05:41,685 - INFO  [Thread-67:DataStorage@160] - Generated new storageID DS-2a8587d8-50ed-4468-8fda-93f2eecf7863 for directory /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2 
2025-03-11 12:05:41,695 - INFO  [Thread-67:BlockPoolSliceStorage@255] - Analyzing storage directories for bpid BP-2070535275-192.168.1.5-1741694740280
2025-03-11 12:05:41,695 - INFO  [Thread-67:Storage$StorageDirectory@907] - Locking is disabled for /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1/current/BP-2070535275-192.168.1.5-1741694740280
2025-03-11 12:05:41,696 - INFO  [Thread-67:BlockPoolSliceStorage@168] - Block pool storage directory for location [DISK]file:/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1 and block pool id BP-2070535275-192.168.1.5-1741694740280 is not formatted. Formatting ...
2025-03-11 12:05:41,696 - INFO  [Thread-67:BlockPoolSliceStorage@284] - Formatting block pool BP-2070535275-192.168.1.5-1741694740280 directory /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1/current/BP-2070535275-192.168.1.5-1741694740280/current
2025-03-11 12:05:41,709 - INFO  [Thread-67:BlockPoolSliceStorage@255] - Analyzing storage directories for bpid BP-2070535275-192.168.1.5-1741694740280
2025-03-11 12:05:41,709 - INFO  [Thread-67:Storage$StorageDirectory@907] - Locking is disabled for /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2/current/BP-2070535275-192.168.1.5-1741694740280
2025-03-11 12:05:41,709 - INFO  [Thread-67:BlockPoolSliceStorage@168] - Block pool storage directory for location [DISK]file:/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2 and block pool id BP-2070535275-192.168.1.5-1741694740280 is not formatted. Formatting ...
2025-03-11 12:05:41,709 - INFO  [Thread-67:BlockPoolSliceStorage@284] - Formatting block pool BP-2070535275-192.168.1.5-1741694740280 directory /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2/current/BP-2070535275-192.168.1.5-1741694740280/current
2025-03-11 12:05:41,711 - INFO  [Thread-67:DataNode@1813] - Setting up storage: nsid=1783479077;bpid=BP-2070535275-192.168.1.5-1741694740280;lv=-57;nsInfo=lv=-67;cid=testClusterID;nsid=1783479077;c=1741694740280;bpid=BP-2070535275-192.168.1.5-1741694740280;dnuuid=null
2025-03-11 12:05:41,712 - INFO  [Thread-67:DataNode@1611] - Generated and persisted new Datanode UUID c63522b4-09a7-47b9-b927-edbc4720a554
2025-03-11 12:05:41,719 - INFO  [Thread-67:FsDatasetImpl@322] - The datanode lock is a read write lock
2025-03-11 12:05:41,720 - INFO  [Socket Reader #1 for port 0:Server$Connection@2189] - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS) from 127.0.0.1:44351
2025-03-11 12:05:41,729 - INFO  [Thread-67:RoundRobinVolumeChoosingPolicy@67] - Round robin volume choosing policy initialized: dfs.datanode.round-robin-volume-choosing-policy.additional-available-space = 0
2025-03-11 12:05:41,746 - WARN  [IPC Server handler 1 on default port 35431:ShellBasedUnixGroupsMapping@218] - unable to return groups for user hdfs
PartialGroupNameException The user name 'hdfs' is not found. id: 'hdfs': no such user
id: 'hdfs': no such user

	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.resolvePartialGroupNames(ShellBasedUnixGroupsMapping.java:291)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:215)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroupsSet(ShellBasedUnixGroupsMapping.java:123)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroupsSet(JniBasedUnixGroupsMappingWithFallback.java:67)
	at org.apache.hadoop.security.Groups$GroupCacheLoader.fetchGroupSet(Groups.java:415)
	at org.apache.hadoop.security.Groups$GroupCacheLoader.load(Groups.java:353)
	at org.apache.hadoop.security.Groups$GroupCacheLoader.load(Groups.java:302)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache.get(LocalCache.java:3962)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3985)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4946)
	at org.apache.hadoop.security.Groups.getGroupInternal(Groups.java:260)
	at org.apache.hadoop.security.Groups.getGroupsSet(Groups.java:232)
	at org.apache.hadoop.security.UserGroupInformation.getGroupsSet(UserGroupInformation.java:1756)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:106)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.getPermissionChecker(FSDirectory.java:1867)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.getPermissionChecker(FSDirectory.java:1856)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3391)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkSuperuserPrivilege(FSNamesystem.java:8964)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkSuperuserPrivilege(FSNamesystem.java:5302)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.datanodeReport(FSNamesystem.java:4925)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getDatanodeReport(NameNodeRpcServer.java:1266)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getDatanodeReport(ClientNamenodeProtocolServerSideTranslatorPB.java:888)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1162)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1085)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1900)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3099)
2025-03-11 12:05:41,766 - INFO  [Listener at localhost/46265:MiniDFSCluster@2859] - dnInfo.length != numDataNodes
2025-03-11 12:05:41,766 - INFO  [Listener at localhost/46265:MiniDFSCluster@2780] - Waiting for cluster to become active
2025-03-11 12:05:41,778 - INFO  [Thread-67:FsVolumeList@365] - Added new volume: DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b
2025-03-11 12:05:41,778 - INFO  [Thread-67:FsDatasetImpl@524] - Added volume - [DISK]file:/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1, StorageType: DISK
2025-03-11 12:05:41,779 - INFO  [Thread-67:FsVolumeList@365] - Added new volume: DS-2a8587d8-50ed-4468-8fda-93f2eecf7863
2025-03-11 12:05:41,779 - INFO  [Thread-67:FsDatasetImpl@524] - Added volume - [DISK]file:/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2, StorageType: DISK
2025-03-11 12:05:41,781 - INFO  [Thread-67:MemoryMappableBlockLoader@47] - Initializing cache loader: MemoryMappableBlockLoader.
2025-03-11 12:05:41,783 - INFO  [Thread-67:FsDatasetImpl@2546] - Registered FSDatasetState MBean
2025-03-11 12:05:41,785 - INFO  [Thread-67:FsDatasetImpl@3089] - Adding block pool BP-2070535275-192.168.1.5-1741694740280
2025-03-11 12:05:41,786 - INFO  [Thread-87:FsVolumeList$2@478] - Scanning block pool BP-2070535275-192.168.1.5-1741694740280 on volume /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1...
2025-03-11 12:05:41,786 - INFO  [Thread-88:FsVolumeList$2@478] - Scanning block pool BP-2070535275-192.168.1.5-1741694740280 on volume /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2...
2025-03-11 12:05:41,792 - WARN  [Thread-87:BlockPoolSlice@305] - dfsUsed file missing in /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1/current/BP-2070535275-192.168.1.5-1741694740280/current, will proceed with Du for space computation calculation, 
2025-03-11 12:05:41,792 - WARN  [Thread-88:BlockPoolSlice@305] - dfsUsed file missing in /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2/current/BP-2070535275-192.168.1.5-1741694740280/current, will proceed with Du for space computation calculation, 
2025-03-11 12:05:41,806 - INFO  [Thread-88:FsVolumeList$2@483] - Time taken to scan block pool BP-2070535275-192.168.1.5-1741694740280 on /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2: 20ms
2025-03-11 12:05:41,806 - INFO  [Thread-87:FsVolumeList$2@483] - Time taken to scan block pool BP-2070535275-192.168.1.5-1741694740280 on /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1: 20ms
2025-03-11 12:05:41,806 - INFO  [Thread-67:FsVolumeList@503] - Total time to scan all replicas for block pool BP-2070535275-192.168.1.5-1741694740280: 22ms
2025-03-11 12:05:41,807 - INFO  [Thread-91:FsVolumeList$1@253] - Adding replicas to map for block pool BP-2070535275-192.168.1.5-1741694740280 on volume /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1...
2025-03-11 12:05:41,807 - INFO  [Thread-92:FsVolumeList$1@253] - Adding replicas to map for block pool BP-2070535275-192.168.1.5-1741694740280 on volume /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2...
2025-03-11 12:05:41,807 - INFO  [Thread-91:BlockPoolSlice@921] - Replica Cache file: /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1/current/BP-2070535275-192.168.1.5-1741694740280/current/replicas doesn't exist 
2025-03-11 12:05:41,807 - INFO  [Thread-92:BlockPoolSlice@921] - Replica Cache file: /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2/current/BP-2070535275-192.168.1.5-1741694740280/current/replicas doesn't exist 
2025-03-11 12:05:41,808 - INFO  [Thread-92:FsVolumeList$1@258] - Time to add replicas to map for block pool BP-2070535275-192.168.1.5-1741694740280 on volume /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2: 1ms
2025-03-11 12:05:41,816 - INFO  [Thread-91:FsVolumeList$1@258] - Time to add replicas to map for block pool BP-2070535275-192.168.1.5-1741694740280 on volume /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1: 10ms
2025-03-11 12:05:41,817 - INFO  [Thread-67:FsVolumeList@279] - Total time to add all replicas to map for block pool BP-2070535275-192.168.1.5-1741694740280: 10ms
2025-03-11 12:05:41,817 - INFO  [Thread-67:ThrottledAsyncChecker@137] - Scheduling a check for /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1
2025-03-11 12:05:41,821 - INFO  [Thread-67:DatasetVolumeChecker@224] - Scheduled health check for volume /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1
2025-03-11 12:05:41,822 - INFO  [Thread-67:ThrottledAsyncChecker@137] - Scheduling a check for /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2
2025-03-11 12:05:41,822 - INFO  [Thread-67:DatasetVolumeChecker@224] - Scheduled health check for volume /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2
2025-03-11 12:05:41,824 - INFO  [VolumeScannerThread(/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2):VolumeScanner@385] - Now scanning bpid BP-2070535275-192.168.1.5-1741694740280 on volume /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2
2025-03-11 12:05:41,824 - INFO  [VolumeScannerThread(/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1):VolumeScanner@385] - Now scanning bpid BP-2070535275-192.168.1.5-1741694740280 on volume /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1
2025-03-11 12:05:41,825 - WARN  [Thread-67:DirectoryScanner@301] - dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2025-03-11 12:05:41,825 - INFO  [VolumeScannerThread(/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1):VolumeScanner@505] - VolumeScanner(/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1, DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b): finished scanning block pool BP-2070535275-192.168.1.5-1741694740280
2025-03-11 12:05:41,825 - INFO  [VolumeScannerThread(/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2):VolumeScanner@505] - VolumeScanner(/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2, DS-2a8587d8-50ed-4468-8fda-93f2eecf7863): finished scanning block pool BP-2070535275-192.168.1.5-1741694740280
2025-03-11 12:05:41,825 - INFO  [Thread-67:DirectoryScanner@366] - Periodic Directory Tree Verification scan starting in 8728171ms with interval of 21600000ms and throttle limit of -1ms/s
2025-03-11 12:05:41,829 - INFO  [BP-2070535275-192.168.1.5-1741694740280 heartbeating to localhost/127.0.0.1:35431:BPServiceActor@812] - Block pool BP-2070535275-192.168.1.5-1741694740280 (Datanode Uuid c63522b4-09a7-47b9-b927-edbc4720a554) service to localhost/127.0.0.1:35431 beginning handshake with NN
2025-03-11 12:05:41,836 - INFO  [VolumeScannerThread(/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1):VolumeScanner@402] - VolumeScanner(/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1, DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b): no suitable block pools found to scan.  Waiting 1814399988 ms.
2025-03-11 12:05:41,836 - INFO  [VolumeScannerThread(/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2):VolumeScanner@402] - VolumeScanner(/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2, DS-2a8587d8-50ed-4468-8fda-93f2eecf7863): no suitable block pools found to scan.  Waiting 1814399988 ms.
2025-03-11 12:05:41,841 - INFO  [IPC Server handler 2 on default port 35431:DatanodeManager@1154] - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40477, datanodeUuid=c63522b4-09a7-47b9-b927-edbc4720a554, infoPort=0, infoSecurePort=36845, ipcPort=46265, storageInfo=lv=-57;cid=testClusterID;nsid=1783479077;c=1741694740280) storage c63522b4-09a7-47b9-b927-edbc4720a554
2025-03-11 12:05:41,842 - INFO  [IPC Server handler 2 on default port 35431:NetworkTopology@149] - Adding a new node: /default-rack/127.0.0.1:40477
2025-03-11 12:05:41,843 - INFO  [IPC Server handler 2 on default port 35431:BlockReportLeaseManager@200] - Registered DN c63522b4-09a7-47b9-b927-edbc4720a554 (127.0.0.1:40477).
2025-03-11 12:05:41,849 - INFO  [BP-2070535275-192.168.1.5-1741694740280 heartbeating to localhost/127.0.0.1:35431:BPServiceActor@840] - Block pool BP-2070535275-192.168.1.5-1741694740280 (Datanode Uuid c63522b4-09a7-47b9-b927-edbc4720a554) service to localhost/127.0.0.1:35431 successfully registered with NN
2025-03-11 12:05:41,849 - INFO  [BP-2070535275-192.168.1.5-1741694740280 heartbeating to localhost/127.0.0.1:35431:DataNode@1680] - Block token params received from NN: for block pool BP-2070535275-192.168.1.5-1741694740280 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2025-03-11 12:05:41,849 - INFO  [BP-2070535275-192.168.1.5-1741694740280 heartbeating to localhost/127.0.0.1:35431:BlockTokenSecretManager@155] - Block token key range: [0, 2147483647)
2025-03-11 12:05:41,850 - INFO  [BP-2070535275-192.168.1.5-1741694740280 heartbeating to localhost/127.0.0.1:35431:BlockTokenSecretManager@229] - Setting block keys. BlockPool = BP-2070535275-192.168.1.5-1741694740280 .
2025-03-11 12:05:41,850 - INFO  [BP-2070535275-192.168.1.5-1741694740280 heartbeating to localhost/127.0.0.1:35431:BPServiceActor@673] - For namenode localhost/127.0.0.1:35431 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2025-03-11 12:05:41,850 - INFO  [ibr-executor-0:BPServiceActor$IBRTaskHandler@1139] - Starting IBR Task Handler.
2025-03-11 12:05:41,860 - INFO  [IPC Server handler 3 on default port 35431:DatanodeDescriptor@1010] - Adding new storage ID DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b for DN 127.0.0.1:40477
2025-03-11 12:05:41,860 - INFO  [IPC Server handler 3 on default port 35431:DatanodeDescriptor@1010] - Adding new storage ID DS-2a8587d8-50ed-4468-8fda-93f2eecf7863 for DN 127.0.0.1:40477
2025-03-11 12:05:41,870 - INFO  [Listener at localhost/46265:MiniDFSCluster@2835] - Cluster is active
2025-03-11 12:05:41,876 - INFO  [Listener at localhost/46265:MiniDFSCluster@2835] - Cluster is active
2025-03-11 12:05:41,878 - INFO  [Block report processor:BlockManager@2777] - BLOCK* processReport 0x689b254dc7c3f1a8: Processing first storage report for DS-2a8587d8-50ed-4468-8fda-93f2eecf7863 from datanode DatanodeRegistration(127.0.0.1:40477, datanodeUuid=c63522b4-09a7-47b9-b927-edbc4720a554, infoPort=0, infoSecurePort=36845, ipcPort=46265, storageInfo=lv=-57;cid=testClusterID;nsid=1783479077;c=1741694740280)
2025-03-11 12:05:41,879 - INFO  [Block report processor:BlockManager@2809] - BLOCK* processReport 0x689b254dc7c3f1a8: from storage DS-2a8587d8-50ed-4468-8fda-93f2eecf7863 node DatanodeRegistration(127.0.0.1:40477, datanodeUuid=c63522b4-09a7-47b9-b927-edbc4720a554, infoPort=0, infoSecurePort=36845, ipcPort=46265, storageInfo=lv=-57;cid=testClusterID;nsid=1783479077;c=1741694740280), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2025-03-11 12:05:41,879 - INFO  [Block report processor:BlockManager@2777] - BLOCK* processReport 0x689b254dc7c3f1a8: Processing first storage report for DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b from datanode DatanodeRegistration(127.0.0.1:40477, datanodeUuid=c63522b4-09a7-47b9-b927-edbc4720a554, infoPort=0, infoSecurePort=36845, ipcPort=46265, storageInfo=lv=-57;cid=testClusterID;nsid=1783479077;c=1741694740280)
2025-03-11 12:05:41,879 - INFO  [Block report processor:BlockManager@2809] - BLOCK* processReport 0x689b254dc7c3f1a8: from storage DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b node DatanodeRegistration(127.0.0.1:40477, datanodeUuid=c63522b4-09a7-47b9-b927-edbc4720a554, infoPort=0, infoSecurePort=36845, ipcPort=46265, storageInfo=lv=-57;cid=testClusterID;nsid=1783479077;c=1741694740280), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2025-03-11 12:05:41,889 - INFO  [BP-2070535275-192.168.1.5-1741694740280 heartbeating to localhost/127.0.0.1:35431:BPServiceActor@457] - Successfully sent block report 0x689b254dc7c3f1a8 to namenode: localhost/127.0.0.1:35431,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msecs to generate and 19 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2025-03-11 12:05:41,890 - INFO  [Command processor:BPOfferService@763] - Got finalize command for block pool BP-2070535275-192.168.1.5-1741694740280
2025-03-11 12:05:41,933 - INFO  [IPC Server handler 8 on default port 35431:FSDirWriteFileOp@802] - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:40477 for /file1
2025-03-11 12:05:42,101 - INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-580814008_11 at /127.0.0.1:60790 [Receiving block BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001]:DataXceiver@748] - Receiving BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001 src: /127.0.0.1:60790 dest: /127.0.0.1:40477
2025-03-11 12:05:42,117 - INFO  [PacketResponder: BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001, type=LAST_IN_PIPELINE:BlockReceiver$PacketResponder@1555] - src: /127.0.0.1:60790, dest: /127.0.0.1:40477, volume: /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-580814008_11, offset: 0, srvID: c63522b4-09a7-47b9-b927-edbc4720a554, blockid: BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001, duration(ns): 3931184
2025-03-11 12:05:42,117 - INFO  [PacketResponder: BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001, type=LAST_IN_PIPELINE:BlockReceiver$PacketResponder@1528] - PacketResponder: BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2025-03-11 12:05:42,121 - INFO  [IPC Server handler 0 on default port 35431:FSNamesystem@3269] - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /file1
2025-03-11 12:05:42,523 - INFO  [IPC Server handler 2 on default port 35431:FSNamesystem@3222] - DIR* completeFile: /file1 is closed by DFSClient_NONMAPREDUCE_-580814008_11
2025-03-11 12:05:42,566 - WARN  [DataXceiver for client DFSClient_NONMAPREDUCE_742191629_11 at /127.0.0.1:60802 [Sending block BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001]:DataXceiver@647] - DatanodeRegistration(127.0.0.1:40477, datanodeUuid=c63522b4-09a7-47b9-b927-edbc4720a554, infoPort=0, infoSecurePort=36845, ipcPort=46265, storageInfo=lv=-57;cid=testClusterID;nsid=1783479077;c=1741694740280):Got exception while serving BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001 to /127.0.0.1:60802
org.apache.hadoop.hdfs.server.datanode.DiskFileCorruptException: A disk IO error occurred
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:596)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:812)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:759)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:611)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:156)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:108)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:293)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: Input/output error
	at java.io.FileInputStream.readBytes(Native Method)
	at java.io.FileInputStream.read(FileInputStream.java:255)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider$WrappedFileInputStream.read(FileIoProvider.java:882)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.ReplicaInputStreams.readDataFully(ReplicaInputStreams.java:85)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:593)
	... 7 more
2025-03-11 12:05:42,567 - ERROR [DataXceiver for client DFSClient_NONMAPREDUCE_742191629_11 at /127.0.0.1:60802 [Sending block BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001]:DataXceiver@325] - 127.0.0.1:40477:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:60802 dst: /127.0.0.1:40477
org.apache.hadoop.hdfs.server.datanode.DiskFileCorruptException: A disk IO error occurred
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:596)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:812)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:759)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:611)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:156)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:108)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:293)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: Input/output error
	at java.io.FileInputStream.readBytes(Native Method)
	at java.io.FileInputStream.read(FileInputStream.java:255)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider$WrappedFileInputStream.read(FileIoProvider.java:882)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.ReplicaInputStreams.readDataFully(ReplicaInputStreams.java:85)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:593)
	... 7 more
2025-03-11 12:05:42,567 - WARN  [hedgedRead-0:DFSInputStream@1260] - Connection failure: Failed to connect to /127.0.0.1:40477 for file /file1 for block BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001:java.io.IOException: Premature EOF reading from org.apache.hadoop.security.SaslInputStream@71d3a4a7
java.io.IOException: Premature EOF reading from org.apache.hadoop.security.SaslInputStream@71d3a4a7
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.readChannelFully(PacketReceiver.java:268)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:217)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:144)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:112)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.readNextPacket(BlockReaderRemote.java:187)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.read(BlockReaderRemote.java:169)
	at org.apache.hadoop.hdfs.DFSInputStream.actualGetFromOneDataNode(DFSInputStream.java:1212)
	at org.apache.hadoop.hdfs.DFSInputStream$2.call(DFSInputStream.java:1174)
	at org.apache.hadoop.hdfs.DFSInputStream$2.call(DFSInputStream.java:1170)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-11 12:05:42,567 - WARN  [Listener at localhost/46265:DFSInputStream@1107] - No live nodes contain block BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001 after checking nodes = [DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]], ignoredNodes = [DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]]
2025-03-11 12:05:42,568 - INFO  [VolumeScannerThread(/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1):VolumeScanner@402] - VolumeScanner(/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1, DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b): no suitable block pools found to scan.  Waiting 1814399256 ms.
2025-03-11 12:05:42,568 - INFO  [Listener at localhost/46265:DFSInputStream@1016] - Could not obtain BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001 from any node:  No live nodes contain current block Block locations: DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK] Dead nodes:  DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK] Ignored nodes:  DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]. Will get new block locations from namenode and retry...
2025-03-11 12:05:42,568 - WARN  [Listener at localhost/46265:DFSInputStream@1035] - DFS chooseDataNode: got # 1 IOException, will wait for 13.918018682001932 msec.
2025-03-11 12:05:42,583 - WARN  [Listener at localhost/46265:DFSInputStream@1107] - No live nodes contain block BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001 after checking nodes = [DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]], ignoredNodes = [DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]]
2025-03-11 12:05:42,583 - INFO  [Listener at localhost/46265:DFSInputStream@1016] - Could not obtain BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001 from any node:  No live nodes contain current block Block locations: DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK] Dead nodes:  Ignored nodes:  DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]. Will get new block locations from namenode and retry...
2025-03-11 12:05:42,583 - WARN  [Listener at localhost/46265:DFSInputStream@1035] - DFS chooseDataNode: got # 2 IOException, will wait for 5986.300037292456 msec.
2025-03-11 12:05:48,572 - WARN  [Listener at localhost/46265:DFSInputStream@1107] - No live nodes contain block BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001 after checking nodes = [DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]], ignoredNodes = [DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]]
2025-03-11 12:05:48,572 - INFO  [Listener at localhost/46265:DFSInputStream@1016] - Could not obtain BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001 from any node:  No live nodes contain current block Block locations: DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK] Dead nodes:  Ignored nodes:  DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]. Will get new block locations from namenode and retry...
2025-03-11 12:05:48,572 - WARN  [Listener at localhost/46265:DFSInputStream@1035] - DFS chooseDataNode: got # 3 IOException, will wait for 14965.651483850525 msec.
2025-03-11 12:06:03,550 - WARN  [hedgedRead-0:BlockReaderFactory@772] - I/O error constructing remote block reader.
java.io.IOException: DIGEST-MD5: IO error acquiring password
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil.readSaslMessageAndNegotiatedCipherOption(DataTransferSaslUtil.java:475)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.doSaslHandshake(SaslDataTransferClient.java:573)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.getSaslStreams(SaslDataTransferClient.java:446)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.send(SaslDataTransferClient.java:289)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.checkTrustAndSend(SaslDataTransferClient.java:236)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.peerSend(SaslDataTransferClient.java:170)
	at org.apache.hadoop.hdfs.DFSUtilClient.peerFromSocketAndKey(DFSUtilClient.java:822)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3052)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:829)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:754)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:381)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:755)
	at org.apache.hadoop.hdfs.DFSInputStream.actualGetFromOneDataNode(DFSInputStream.java:1202)
	at org.apache.hadoop.hdfs.DFSInputStream$2.call(DFSInputStream.java:1174)
	at org.apache.hadoop.hdfs.DFSInputStream$2.call(DFSInputStream.java:1170)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-11 12:06:03,550 - WARN  [hedgedRead-0:DFSInputStream@1260] - Connection failure: Failed to connect to /127.0.0.1:40477 for file /file1 for block BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001:java.io.IOException: DIGEST-MD5: IO error acquiring password
java.io.IOException: DIGEST-MD5: IO error acquiring password
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil.readSaslMessageAndNegotiatedCipherOption(DataTransferSaslUtil.java:475)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.doSaslHandshake(SaslDataTransferClient.java:573)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.getSaslStreams(SaslDataTransferClient.java:446)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.send(SaslDataTransferClient.java:289)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.checkTrustAndSend(SaslDataTransferClient.java:236)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.peerSend(SaslDataTransferClient.java:170)
	at org.apache.hadoop.hdfs.DFSUtilClient.peerFromSocketAndKey(DFSUtilClient.java:822)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3052)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:829)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:754)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:381)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:755)
	at org.apache.hadoop.hdfs.DFSInputStream.actualGetFromOneDataNode(DFSInputStream.java:1202)
	at org.apache.hadoop.hdfs.DFSInputStream$2.call(DFSInputStream.java:1174)
	at org.apache.hadoop.hdfs.DFSInputStream$2.call(DFSInputStream.java:1170)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-11 12:06:03,550 - WARN  [Listener at localhost/46265:DFSInputStream@1107] - No live nodes contain block BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001 after checking nodes = [DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]], ignoredNodes = [DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]]
2025-03-11 12:06:03,550 - INFO  [Listener at localhost/46265:DFSInputStream@1016] - Could not obtain BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001 from any node:  No live nodes contain current block Block locations: DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK] Dead nodes:  DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK] Ignored nodes:  DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]. Will get new block locations from namenode and retry...
2025-03-11 12:06:03,550 - WARN  [Listener at localhost/46265:DFSInputStream@1035] - DFS chooseDataNode: got # 1 IOException, will wait for 186.65127184524323 msec.
2025-03-11 12:06:03,744 - INFO  [Socket Reader #1 for port 0:Server$Connection@2189] - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS) from 127.0.0.1:35767
2025-03-11 12:06:03,747 - WARN  [Listener at localhost/46265:DFSInputStream@1107] - No live nodes contain block BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001 after checking nodes = [DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]], ignoredNodes = [DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]]
2025-03-11 12:06:03,747 - INFO  [Listener at localhost/46265:DFSInputStream@1016] - Could not obtain BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001 from any node:  No live nodes contain current block Block locations: DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK] Dead nodes:  Ignored nodes:  DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]. Will get new block locations from namenode and retry...
2025-03-11 12:06:03,747 - WARN  [Listener at localhost/46265:DFSInputStream@1035] - DFS chooseDataNode: got # 2 IOException, will wait for 5893.46466997891 msec.
2025-03-11 12:06:09,642 - WARN  [Listener at localhost/46265:DFSInputStream@1107] - No live nodes contain block BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001 after checking nodes = [DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]], ignoredNodes = [DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]]
2025-03-11 12:06:09,642 - INFO  [Listener at localhost/46265:DFSInputStream@1016] - Could not obtain BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001 from any node:  No live nodes contain current block Block locations: DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK] Dead nodes:  Ignored nodes:  DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]. Will get new block locations from namenode and retry...
2025-03-11 12:06:09,642 - WARN  [Listener at localhost/46265:DFSInputStream@1035] - DFS chooseDataNode: got # 3 IOException, will wait for 13717.097671300558 msec.
2025-03-11 12:06:23,364 - INFO  [Socket Reader #1 for port 0:Server$Connection@2189] - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS) from 127.0.0.1:34817
2025-03-11 12:06:23,375 - WARN  [IPC Server handler 2 on default port 35431:ShellBasedUnixGroupsMapping@218] - unable to return groups for user hdfs
PartialGroupNameException The user name 'hdfs' is not found. id: 'hdfs': no such user
id: 'hdfs': no such user

	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.resolvePartialGroupNames(ShellBasedUnixGroupsMapping.java:291)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:215)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroupsSet(ShellBasedUnixGroupsMapping.java:123)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroupsSet(JniBasedUnixGroupsMappingWithFallback.java:67)
	at org.apache.hadoop.security.Groups$GroupCacheLoader.fetchGroupSet(Groups.java:415)
	at org.apache.hadoop.security.Groups$GroupCacheLoader.load(Groups.java:353)
	at org.apache.hadoop.security.Groups$GroupCacheLoader.load(Groups.java:302)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache.get(LocalCache.java:3962)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3985)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4946)
	at org.apache.hadoop.security.Groups.getGroupInternal(Groups.java:260)
	at org.apache.hadoop.security.Groups.getGroupsSet(Groups.java:232)
	at org.apache.hadoop.security.UserGroupInformation.getGroupsSet(UserGroupInformation.java:1756)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:106)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.getPermissionChecker(FSDirectory.java:1867)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.getPermissionChecker(FSDirectory.java:1856)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3391)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2169)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:768)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:464)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1162)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1085)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1900)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3099)
2025-03-11 12:06:23,376 - WARN  [Listener at localhost/46265:DFSInputStream@1107] - No live nodes contain block BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001 after checking nodes = [DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]], ignoredNodes = [DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]]
2025-03-11 12:06:23,376 - WARN  [Listener at localhost/46265:DFSInputStream@1006] - Could not obtain block: BP-2070535275-192.168.1.5-1741694740280:blk_1073741825_1001 file=/file1 No live nodes contain current block Block locations: DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK] Dead nodes:  Ignored nodes:  DatanodeInfoWithStorage[127.0.0.1:40477,DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b,DISK]. Throwing a BlockMissingException
2025-03-11 12:06:23,377 - INFO  [Listener at localhost/46265:MiniDFSCluster@2116] - Shutting down the Mini HDFS Cluster
2025-03-11 12:06:23,377 - INFO  [Listener at localhost/46265:MiniDFSCluster@2164] - Shutting down DataNode 0
2025-03-11 12:06:23,377 - INFO  [Listener at localhost/46265:DirectoryScanner@429] - Shutdown has been called
2025-03-11 12:06:23,377 - INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@36efed27:DataXceiverServer@396] - Closing all peers.
2025-03-11 12:06:23,385 - INFO  [VolumeScannerThread(/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1):VolumeScanner@672] - VolumeScanner(/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1, DS-6fca25af-682a-4bb3-8f3b-fad5b8e16f0b) exiting.
2025-03-11 12:06:23,386 - INFO  [VolumeScannerThread(/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2):VolumeScanner@672] - VolumeScanner(/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2, DS-2a8587d8-50ed-4468-8fda-93f2eecf7863) exiting.
2025-03-11 12:06:23,390 - INFO  [Listener at localhost/46265:ContextHandler@1153] - Stopped o.e.j.w.WebAppContext@bc8c9ac{datanode,/,null,STOPPED}{file:/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/systems/hdfs-16332/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode}
2025-03-11 12:06:23,392 - INFO  [Listener at localhost/46265:AbstractConnector@381] - Stopped ServerConnector@2896a8b5{HTTP/1.1, (http/1.1)}{localhost:0}
2025-03-11 12:06:23,392 - INFO  [Listener at localhost/46265:HouseKeeper@149] - node0 Stopped scavenging
2025-03-11 12:06:23,392 - INFO  [Listener at localhost/46265:ContextHandler@1153] - Stopped o.e.j.s.ServletContextHandler@6846882a{static,/static,file:///home/sebastiaoamaro/phd/torefidevel/rw/Anduril/systems/hdfs-16332/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,STOPPED}
2025-03-11 12:06:23,393 - INFO  [Listener at localhost/46265:DataNode@2146] - Waiting up to 30 seconds for transfer threads to complete
2025-03-11 12:06:23,393 - INFO  [Listener at localhost/46265:Server@3553] - Stopping server on 46265
2025-03-11 12:06:23,393 - INFO  [IPC Server listener on 0:Server$Listener@1503] - Stopping IPC Server listener on 0
2025-03-11 12:06:23,393 - INFO  [IPC Server Responder:Server$Responder@1636] - Stopping IPC Server Responder
2025-03-11 12:06:23,394 - ERROR [Command processor:BPServiceActor$CommandProcessingThread@1410] - Command processor encountered interrupt and exit.
2025-03-11 12:06:23,394 - WARN  [BP-2070535275-192.168.1.5-1741694740280 heartbeating to localhost/127.0.0.1:35431:IncrementalBlockReportManager@160] - IncrementalBlockReportManager interrupted
2025-03-11 12:06:23,394 - WARN  [Command processor:BPServiceActor$CommandProcessingThread@1394] - Ending command processor service for: Thread[Command processor,5,main]
2025-03-11 12:06:23,394 - WARN  [ibr-executor-0:IncrementalBlockReportManager@160] - IncrementalBlockReportManager interrupted
2025-03-11 12:06:23,394 - WARN  [BP-2070535275-192.168.1.5-1741694740280 heartbeating to localhost/127.0.0.1:35431:BPServiceActor@918] - Ending block pool service for: Block pool BP-2070535275-192.168.1.5-1741694740280 (Datanode Uuid c63522b4-09a7-47b9-b927-edbc4720a554) service to localhost/127.0.0.1:35431
2025-03-11 12:06:23,394 - INFO  [BP-2070535275-192.168.1.5-1741694740280 heartbeating to localhost/127.0.0.1:35431:BlockPoolManager@103] - Removed Block pool BP-2070535275-192.168.1.5-1741694740280 (Datanode Uuid c63522b4-09a7-47b9-b927-edbc4720a554)
2025-03-11 12:06:23,394 - INFO  [BP-2070535275-192.168.1.5-1741694740280 heartbeating to localhost/127.0.0.1:35431:FsDatasetImpl@3122] - Removing block pool BP-2070535275-192.168.1.5-1741694740280
2025-03-11 12:06:23,395 - WARN  [refreshUsed-/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data1/current/BP-2070535275-192.168.1.5-1741694740280:CachingGetSpaceUsed$RefreshThread@211] - Thread Interrupted waiting to refresh disk information: sleep interrupted
2025-03-11 12:06:23,395 - WARN  [refreshUsed-/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/data/data2/current/BP-2070535275-192.168.1.5-1741694740280:CachingGetSpaceUsed$RefreshThread@211] - Thread Interrupted waiting to refresh disk information: sleep interrupted
2025-03-11 12:06:23,395 - INFO  [Listener at localhost/46265:FsDatasetAsyncDiskService@201] - Shutting down all async disk service threads
2025-03-11 12:06:23,395 - INFO  [Listener at localhost/46265:FsDatasetAsyncDiskService@209] - All async disk service threads have been shut down
2025-03-11 12:06:23,395 - INFO  [Listener at localhost/46265:RamDiskAsyncLazyPersistService@186] - Shutting down all async lazy persist service threads
2025-03-11 12:06:23,395 - INFO  [Listener at localhost/46265:RamDiskAsyncLazyPersistService@193] - All async lazy persist service threads have been shut down
2025-03-11 12:06:23,395 - INFO  [Listener at localhost/46265:DataNode@2235] - Shutdown complete.
2025-03-11 12:06:23,395 - INFO  [Listener at localhost/46265:MiniDFSCluster@2197] - Shutting down the namenode
2025-03-11 12:06:23,396 - INFO  [Listener at localhost/46265:FSNamesystem@1493] - Stopping services started for active state
2025-03-11 12:06:23,396 - ERROR [Thread[Thread-31,5,main]:AbstractDelegationTokenSecretManager$ExpiredTokenRemover@722] - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2025-03-11 12:06:23,396 - INFO  [Listener at localhost/46265:FSEditLog@1460] - Ending log segment 1, 8
2025-03-11 12:06:23,396 - INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@106acee6:FSNamesystem$LazyPersistFileScrubber@4662] - LazyPersistFileScrubber was interrupted, exiting
2025-03-11 12:06:23,396 - INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@312e6017:FSNamesystem$NameNodeEditLogRoller@4566] - NameNodeEditLogRoller was interrupted, exiting
2025-03-11 12:06:23,397 - INFO  [Listener at localhost/46265:FSEditLog@796] - Number of transactions: 9 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 1 Number of syncs: 9 SyncTimes(ms): 16 11 
2025-03-11 12:06:23,398 - INFO  [Listener at localhost/46265:FileJournalManager@145] - Finalizing edits file /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2025-03-11 12:06:23,398 - INFO  [Listener at localhost/46265:FileJournalManager@145] - Finalizing edits file /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /home/sebastiaoamaro/phd/torefidevel/rw/Anduril/experiment/hdfs-16332/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2025-03-11 12:06:23,398 - INFO  [FSEditLogAsync:FSEditLogAsync@276] - FSEditLogAsync was interrupted, exiting
2025-03-11 12:06:23,398 - INFO  [Listener at localhost/46265:Server@3553] - Stopping server on 35431
2025-03-11 12:06:23,398 - INFO  [CacheReplicationMonitor(1829593987):CacheReplicationMonitor@169] - Shutting down CacheReplicationMonitor
2025-03-11 12:06:23,398 - INFO  [IPC Server listener on 0:Server$Listener@1503] - Stopping IPC Server listener on 0
2025-03-11 12:06:23,398 - INFO  [IPC Server Responder:Server$Responder@1636] - Stopping IPC Server Responder
2025-03-11 12:06:23,398 - INFO  [RedundancyMonitor:BlockManager$RedundancyMonitor@4931] - Stopping RedundancyMonitor.
2025-03-11 12:06:23,406 - INFO  [Listener at localhost/46265:FSNamesystem@1493] - Stopping services started for active state
2025-03-11 12:06:23,406 - INFO  [Listener at localhost/46265:FSNamesystem@1597] - Stopping services started for standby state
2025-03-11 12:06:23,407 - INFO  [Listener at localhost/46265:ContextHandler@1153] - Stopped o.e.j.w.WebAppContext@ed8a801{hdfs,/,null,STOPPED}{file:/home/sebastiaoamaro/phd/torefidevel/rw/Anduril/systems/hdfs-16332/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs}
2025-03-11 12:06:23,408 - INFO  [Listener at localhost/46265:AbstractConnector@381] - Stopped ServerConnector@5f3ff011{SSL, (ssl, http/1.1)}{localhost:0}
2025-03-11 12:06:23,408 - INFO  [Listener at localhost/46265:HouseKeeper@149] - node0 Stopped scavenging
2025-03-11 12:06:23,408 - INFO  [Listener at localhost/46265:ContextHandler@1153] - Stopped o.e.j.s.ServletContextHandler@26c8965c{static,/static,file:///home/sebastiaoamaro/phd/torefidevel/rw/Anduril/systems/hdfs-16332/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,STOPPED}
2025-03-11 12:06:23,408 - INFO  [Listener at localhost/46265:MetricsSystemImpl@210] - Stopping DataNode metrics system...
2025-03-11 12:06:23,409 - INFO  [Listener at localhost/46265:MetricsSystemImpl@216] - DataNode metrics system stopped.
2025-03-11 12:06:23,409 - INFO  [Listener at localhost/46265:MetricsSystemImpl@611] - DataNode metrics system shutdown complete.
E2025-03-11 12:06:23,414 - INFO  [main:DefaultInternalKdcServerImpl@102] - Default Internal kdc server stopped.
2025-03-11 12:06:24,415 - INFO  [main:MiniKdc@359] - MiniKdc stopped.

Time: 45.177
There was 1 failure:
1) testHedgedFetchBlockByteRangeWithExpiredToken(org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransferExpiredBlockToken)
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:87)
	at org.junit.Assert.assertTrue(Assert.java:42)
	at org.junit.Assert.assertTrue(Assert.java:53)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransferExpiredBlockToken.testHedgedFetchBlockByteRangeWithExpiredToken(TestSaslDataTransferExpiredBlockToken.java:177)

FAILURES!!!
Tests run: 1,  Failures: 1

